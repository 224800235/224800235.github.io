


<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,inital-scale=1,user-scalable=no">
  <title>spark配置，hadoop配置 [ Hexo ]</title>
  <!-- bootstrapcss文件 -->
 <!--  <link rel="stylesheet" href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"> -->
<!--   
<link rel="stylesheet" href="/css/zhl.css">

 -->
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="/css/fork-awesome.min.css">
    
      <link rel="stylesheet" href="/css/zhl.css">
    
  
  
<meta name="generator" content="Hexo 7.3.0"></head>
<body>
<div class="container-fluid">
  <div class="row">
  <div id="wrap" class="col-md-12">
    <div id="header">
	<div id="header-left">
	<h1 id="header-title"> 
	<a href="/">
		Hexo
	</a>
	</h1>
	
	</div>
	<div id="header-right">
		
		
		<a href="/"  title="home"><i class="fa fa-home ">home</i></a>
		
		<a target="_blank" rel="noopener" href="https://github.com/lizehongss/demo_show"  title="demo"><i class="fa fa-code ">demo</i></a>
		
		<a href="/about"  title="about"><i class="fa fa-user ">about</i></a>
		
		<a href="/"  title="music"><i class="fa fa-music ">music</i></a>
		
		
	</div>
</div>

  </div>
  </div>
  <div id="content" class="row">
    <div id="content-left" class="col-md-4">
      

	

	
	<div class="widget-wrap">
		<h3 class="widget-title fa fa-tags">标签</h3>
		<div class="widget tags">
		<a class="tag-span-link" href="/tags/Hadoop/" rel="tag">Hadoop<span class="tag-span-count">1</span></a> <a class="tag-span-link" href="/tags/Spark/" rel="tag">Spark<span class="tag-span-count">1</span></a> <a class="tag-span-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据<span class="tag-span-count">1</span></a>
		</div>
	</div>


	
	<div class="widget-wrap">
		<h3 class="widget-title fa fa-archive">归档</h3>
		<div class="widget">
			<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/">2025</a><span class="archive-list-count">2</span></li></ul>
		</div>
	</div>



    </div>
    <div id="content-right" class="col-md-8">
    
<article id="post">
	<div class="post-title">
  <h1>spark配置，hadoop配置</h1>
  	</div>
  <div class="page-meta">
  	<span class="fa-wrap">
  		<i class="fa fa-clock-o"></i>
  		<span class="date-meta">2025-06-08</span>
  	</span>
  	<span class="fa-wrap">
  		
  		<i class="fa fa-tags"></i>
  		<span class="tags-meta">Spark</span>
  		
  	</span>
  	<span class="fa-wrap">
  		
  	</span>
  </div>
  <div class="post-content">
  <h2 id="Spark基础配置"><a href="#Spark基础配置" class="headerlink" title="Spark基础配置"></a>Spark基础配置</h2><h3 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1. 环境准备"></a>1. 环境准备</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载Spark</span></span><br><span class="line">wget https://archive.apache.org/dist/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压安装</span></span><br><span class="line">tar -zxvf spark-3.3.1-bin-hadoop3.tgz -C /opt/module/</span><br><span class="line"><span class="built_in">mv</span> spark-3.3.1-bin-hadoop3 spark-local</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑/etc/profile.d/my_env.sh</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/opt/module/spark-local</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$SPARK_HOME</span>/sbin</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master <span class="built_in">local</span>[2] \</span><br><span class="line">  <span class="variable">$SPARK_HOME</span>/examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">  10</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- spark-defaults.conf --&gt;</span><br><span class="line">spark.master            yarn</span><br><span class="line">spark.yarn.jars         hdfs:///spark/jars/*</span><br><span class="line">spark.executor.memory   4g</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看Spark作业</span></span><br><span class="line">yarn application -list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看日志</span></span><br><span class="line">yarn logs -applicationId &lt;app_id&gt;</span><br></pre></td></tr></table></figure>
<h2 id="Hadoop基础配置"><a href="#Hadoop基础配置" class="headerlink" title="Hadoop基础配置"></a>Hadoop基础配置</h2><h3 id="1-环境准备-1"><a href="#1-环境准备-1" class="headerlink" title="1. 环境准备"></a>1. 环境准备</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载Hadoop</span></span><br><span class="line">wget https://archive.apache.org/dist/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压安装</span></span><br><span class="line">tar -zxvf hadoop-3.3.1.tar.gz -C /opt/module/</span><br><span class="line"><span class="built_in">mv</span> hadoop-3.3.1 hadoop</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑/etc/profile.d/my_env.sh</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 格式化HDFS</span></span><br><span class="line">hdfs namenode -format</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动HDFS</span></span><br><span class="line">start-dfs.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动YARN</span></span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在spark-env.sh中添加</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> YARN_CONF_DIR=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  <span class="variable">$SPARK_HOME</span>/examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">  10</span><br></pre></td></tr></table></figure>
<h2 id="JDK基础配置"><a href="#JDK基础配置" class="headerlink" title="JDK基础配置"></a>JDK基础配置</h2><h3 id="1-环境准备-2"><a href="#1-环境准备-2" class="headerlink" title="1. 环境准备"></a>1. 环境准备</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载JDK (请替换为实际版本)</span></span><br><span class="line">wget https://download.oracle.com/java/8u161/b13/jdk-8u161-linux-x64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压安装</span></span><br><span class="line">tar -zxvf jdk-8u161-linux-x64.tar.gz -C /opt/module/</span><br><span class="line"><span class="built_in">mv</span> jdk1.8.0_161 java</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑/etc/profile.d/my_env.sh</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/java</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使配置生效</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure>
<h2 id="Zookeeper集群配置"><a href="#Zookeeper集群配置" class="headerlink" title="Zookeeper集群配置"></a>Zookeeper集群配置</h2><h3 id="1-环境准备-3"><a href="#1-环境准备-3" class="headerlink" title="1. 环境准备"></a>1. 环境准备</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载Zookeeper</span></span><br><span class="line">wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压安装</span></span><br><span class="line">tar -zxvf zookeeper-3.4.14.tar.gz -C /opt/module/</span><br><span class="line"><span class="built_in">mv</span> zookeeper-3.4.14 zookeeper</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑/etc/profile.d/my_env.sh</span></span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/opt/module/zookeeper</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$ZOOKEEPER_HOME</span>/bin</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># zoo.cfg</span></span><br><span class="line">tickTime=2000</span><br><span class="line">dataDir=/opt/module/zookeeper/data</span><br><span class="line">clientPort=2181</span><br><span class="line">server.1=hadoop1:2888:3888</span><br><span class="line">server.2=hadoop2:2888:3888</span><br><span class="line">server.3=hadoop3:2888:3888</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动服务</span></span><br><span class="line">zkServer.sh start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">zkServer.sh status</span><br><span class="line"></span><br><span class="line"><span class="comment"># 连接客户端</span></span><br><span class="line">zkCli.sh -server hadoop1:2181</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在hadoop-env.sh中添加</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">&quot;<span class="variable">$HADOOP_OPTS</span> -Djava.security.auth.login.config=/path/to/jaas.conf&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="Spark-Local模式详细配置"><a href="#Spark-Local模式详细配置" class="headerlink" title="Spark Local模式详细配置"></a>Spark Local模式详细配置</h2><h3 id="1-本地模式特点"><a href="#1-本地模式特点" class="headerlink" title="1. 本地模式特点"></a>1. 本地模式特点</h3><ul>
<li>单机运行，无需集群</li>
<li>适合开发测试环境</li>
<li>通过线程模拟分布式计算</li>
</ul>
<h3 id="2-配置参数详解"><a href="#2-配置参数详解" class="headerlink" title="2. 配置参数详解"></a>2. 配置参数详解</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># spark-defaults.conf关键参数</span></span><br><span class="line">spark.master            <span class="built_in">local</span>[4]  <span class="comment"># 使用4个线程</span></span><br><span class="line">spark.driver.memory     2g        <span class="comment"># 驱动内存</span></span><br><span class="line">spark.executor.memory   1g        <span class="comment"># 执行器内存</span></span><br><span class="line">spark.serializer        org.apache.spark.serializer.KryoSerializer</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 带详细参数的运行示例</span></span><br><span class="line">spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master <span class="built_in">local</span>[4] \</span><br><span class="line">  --driver-memory 2g \</span><br><span class="line">  --executor-memory 1g \</span><br><span class="line">  --conf spark.default.parallelism=8 \</span><br><span class="line">  <span class="variable">$SPARK_HOME</span>/examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">  100</span><br></pre></td></tr></table></figure>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启用Web UI监控</span></span><br><span class="line">spark-submit \</span><br><span class="line">  --conf spark.ui.enabled=<span class="literal">true</span> \</span><br><span class="line">  --conf spark.ui.port=4040 \</span><br><span class="line">  --class your.main.class \</span><br><span class="line">  your-app.jar</span><br></pre></td></tr></table></figure>
<h2 id="Spark-Standalone模式配置"><a href="#Spark-Standalone模式配置" class="headerlink" title="Spark Standalone模式配置"></a>Spark Standalone模式配置</h2><h3 id="1-集群架构"><a href="#1-集群架构" class="headerlink" title="1. 集群架构"></a>1. 集群架构</h3><ul>
<li><strong>Master节点</strong>：负责资源调度</li>
<li><strong>Worker节点</strong>：执行具体任务</li>
<li>推荐至少3个节点（1 Master + 2 Workers）</li>
</ul>
<h3 id="2-核心配置"><a href="#2-核心配置" class="headerlink" title="2. 核心配置"></a>2. 核心配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># spark-env.sh</span></span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_HOST=hadoop1</span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_PORT=7077</span><br><span class="line"><span class="built_in">export</span> SPARK_WORKER_CORES=4</span><br><span class="line"><span class="built_in">export</span> SPARK_WORKER_MEMORY=8g</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># workers文件内容</span></span><br><span class="line">hadoop1</span><br><span class="line">hadoop2 </span><br><span class="line">hadoop3</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动集群</span></span><br><span class="line"><span class="variable">$SPARK_HOME</span>/sbin/start-all.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止集群</span></span><br><span class="line"><span class="variable">$SPARK_HOME</span>/sbin/stop-all.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交作业</span></span><br><span class="line">spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master spark://hadoop1:7077 \</span><br><span class="line">  --executor-memory 2G \</span><br><span class="line">  --total-executor-cores 4 \</span><br><span class="line">  <span class="variable">$SPARK_HOME</span>/examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">  100</span><br></pre></td></tr></table></figure>
<h2 id="Spark-HA高可用配置"><a href="#Spark-HA高可用配置" class="headerlink" title="Spark HA高可用配置"></a>Spark HA高可用配置</h2><h3 id="1-架构说明"><a href="#1-架构说明" class="headerlink" title="1. 架构说明"></a>1. 架构说明</h3><ul>
<li><strong>主备Master节点</strong>：通过Zookeeper实现自动故障转移</li>
<li><strong>Worker节点</strong>：注册到当前活跃的Master</li>
<li><strong>Zookeeper集群</strong>：保存集群状态信息</li>
</ul>
<h3 id="2-核心配置-1"><a href="#2-核心配置-1" class="headerlink" title="2. 核心配置"></a>2. 核心配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># spark-env.sh</span></span><br><span class="line"><span class="built_in">export</span> SPARK_DAEMON_JAVA_OPTS=<span class="string">&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=hadoop1:2181,hadoop2:2181,hadoop3:2181&quot;</span></span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_WEBUI_PORT=8080</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在主节点启动</span></span><br><span class="line"><span class="variable">$SPARK_HOME</span>/sbin/start-all.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在备节点启动master</span></span><br><span class="line"><span class="variable">$SPARK_HOME</span>/sbin/start-master.sh</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 必须指定所有master地址</span></span><br><span class="line">spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master spark://hadoop1:7077,hadoop2:7077 \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  <span class="variable">$SPARK_HOME</span>/examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">  100</span><br></pre></td></tr></table></figure>
<h2 id="Spark-on-YARN模式配置"><a href="#Spark-on-YARN模式配置" class="headerlink" title="Spark on YARN模式配置"></a>Spark on YARN模式配置</h2><h3 id="1-架构说明-1"><a href="#1-架构说明-1" class="headerlink" title="1. 架构说明"></a>1. 架构说明</h3><ul>
<li><strong>ResourceManager</strong>：YARN资源管理器</li>
<li><strong>NodeManager</strong>：YARN节点管理器</li>
<li><strong>Spark Driver</strong>：运行在YARN容器中或客户端</li>
<li>支持两种部署模式：cluster和client</li>
</ul>
<h3 id="2-核心配置-2"><a href="#2-核心配置-2" class="headerlink" title="2. 核心配置"></a>2. 核心配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># spark-defaults.conf</span></span><br><span class="line">spark.master                  yarn</span><br><span class="line">spark.yarn.jars               hdfs:///spark/jars/*</span><br><span class="line">spark.executor.memory         4g</span><br><span class="line">spark.executor.cores          2</span><br><span class="line">spark.driver.memory           2g</span><br><span class="line">spark.yarn.am.memory          1g</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定YARN队列</span></span><br><span class="line">spark.yarn.queue              default</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cluster模式</span></span><br><span class="line">spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory 2G \</span><br><span class="line">  --num-executors 4 \</span><br><span class="line">  <span class="variable">$SPARK_HOME</span>/examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">  100</span><br><span class="line"></span><br><span class="line"><span class="comment"># client模式</span></span><br><span class="line">spark-submit \</span><br><span class="line">  --class org.apache.spark.examples.SparkPi \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode client \</span><br><span class="line">  <span class="variable">$SPARK_HOME</span>/examples/jars/spark-examples_2.12-3.1.1.jar \</span><br><span class="line">  100</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment"># 查看YARN应用</span></span><br><span class="line">yarn application -list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看日志</span></span><br><span class="line">yarn logs -applicationId &lt;app_id&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 终止应用</span></span><br><span class="line">yarn application -<span class="built_in">kill</span> &lt;app_id&gt;</span><br></pre></td></tr></table></figure>

	</div>
</article>



    </div>
  </div>
  <div class="row">
<div id="bottom" class="col-md-12"> 
  <div class="bottom-nav">
	
	
	<a href="https://github.com/lizehongss" class="fa fa-github fa-2x" target="_blank" title="Follow me" ></a>
	
	
</div>
<div class="bottom-info">
	&copy; 2025 John Doe<br>
	Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	theme <a href="https://github.com/lizehongss/hexo-theme-zhl" target="_blank">zhl</a>
</div>
</div>
</div>
</div>
<div id="tool">
  <ul>
    <li class="fa fa-angle-up top" id="top"></li>
  </ul>
</div>
  <div class="bg_content">
    <canvas id="canvas"></canvas>
  </div>
  
  <!-- scripts list from theme config.yml -->
  
    <script src="/js/zhl.js"></script>
  
    <script src="/js/bj.js"></script>
  

<!-- jQ cdn  -->
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<!-- bootstrap js cdn-->
<!-- <script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script> -->


</body>
</html>
